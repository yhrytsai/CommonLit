import pandas as pd
from sklearn.model_selection import train_test_split
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import Lasso, SGDRegressor
from xgboost import XGBRegressor
import numpy as np
from sklearn.feature_extraction.text import HashingVectorizer
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVR
import itertools
from sklearn.metrics import make_scorer
from sklearn.metrics import mean_squared_error
import joblib

""" Data description
Columns:
id - unique ID for excerpt
url_legal - URL of source - this is blank in the test set.
license - license of source material - this is blank in the test set.
excerpt - text to predict reading ease of
target - reading ease
standard_error - measure of spread of scores among multiple raters for each excerpt. Not included for test data.
"""
############################### Load data farme, split data ############################################################

data = pd.read_csv('commonlitreadabilityprize/train.csv')
data = data[['excerpt', 'target']]
data['target'] = data['target'].astype(float)
X_train, X_test, y_train, y_test = train_test_split(data['excerpt'], data['target'], test_size=0.2, random_state=123)

print(y_train.describe(), y_test.describe())

dtrain = pd.DataFrame({
    'excerpt': X_train,
    'target': y_train
}).reset_index(drop=True)
dvalid = pd.DataFrame({
    'excerpt': X_test,
    'target': y_test
}).reset_index(drop=True)

del X_train, X_test, y_train, y_test
## ToDo: 1. stratified splitting # 2. Try other splitting proportion 3.Balance data set according to structure in hidden privite set (i.e. propotion of modern texts and sources)

############################### EDA ####################################################################################

""" This step was passed manually and do not reflected in script in view of limited time resources """

sns.histplot(data['target'])
plt.show()


############################### Create pipeline with gridserch #########################################################
# create func for some manual features from text that might be useful for reading ease prediction
def count_capital_char(text):
    count = 0
    for i in text:
        if i.isupper():
            count += 1
    return count


def features_creation(data, col):
    data['character_number'] = data.apply(lambda x: len(x[col]), axis=1)

    data['words_number'] = data.apply(lambda x: len(x[col].split()), axis=1)

    data['capital_character_number'] = data.apply(lambda x: count_capital_char(x[col]), axis=1)

    data['capital_words_number'] = data.apply(lambda x: sum(map(str.isupper, x[col].split())), axis=1)

    data['punctuation_number'] = data.apply(lambda x: sum(map(str.isupper, x[col].split())), axis=1)

    data['sentences_number'] = data.apply(lambda x: x[col].count("."), axis=1)

    data['unique_words_number'] = data.apply(lambda x: len(set(x[col])), axis=1)

    data['wordlength_avg'] = data['character_number'] / data['words_number']

    data['sentlength_avg'] = data['words_number'] / data['sentences_number']

    data['unique_vs_words'] = data['unique_words_number'] / data['words_number']

    return data


dtrain = features_creation(dtrain, 'excerpt')
dvalid = features_creation(dvalid, 'excerpt')

# ColumnTransformer is used to specify column for vectorizing, as for model fitting X contain more columns (especially manually created by func + created after vectorizing in pipeline)
vect_ct = ColumnTransformer([('vectorizer', TfidfVectorizer(),
                              'excerpt')])  # TfidfVectorizer() is equivalent to CountVectorizer followed by TfidfTransformer.

estimators = [('vect', vect_ct), ('model', Lasso())]
pipe = Pipeline(steps=estimators)  # any model to be added as starting point

# Parameters of pipelines can be set using '__' separated parameter names
vect_search_space = [
    {
        'vect__vectorizer': [TfidfVectorizer()],
        # vect__vectorizer__XX - because of ColumnTransformer used for vectorization
        'vect__vectorizer__min_df': [25, 50, 150, 200, 1],
        # min_df - ignore terms that appeared in less than X documents
        'vect__vectorizer__max_df': [0.75, 0.8, 0.85, 1],
        # max_df ignore words appeared in XX% of the documents as they are too commontypically used a value from (0.75-0.85)
    }, {
        'vect__vectorizer': [HashingVectorizer()]
    }]

mod_search_space = [
    {
        'model': [SGDRegressor(random_state=123)],
        'model__alpha': (1e-2, 1e-3),
    }, {
        'model': [XGBRegressor(eval_metric='rmse', seed=123)],
        'model__max_depth': np.linspace(1, 15, 1).round(0).astype(int), # max_depth should be integer
        'model__eta': np.logspace(-3, 0.1, 1),
        'model__subsample': np.linspace(0.5, 1, 1),
    }, {
        'model': [Lasso(random_state=123)],
        'model__alpha': np.logspace(-4, -0.5, 6)
    }, {
        'model': [SVR()],
        'model__kernel': ['poly', 'rbf', 'sigmoid', 'precomputed'],
        'model__gamma': (1e-3, 1e-4),
        'model__C': (1, 10, 100, 1000)
    }
]

# create itertoolled list to grid over both feature creation hyperparameters and models parameters
# https://stackoverflow.com/questions/72418780/sklearn-pipeline-with-multiple-transforms-and-estimators
param_ = [
    {**vect, **mod}
    for vect, mod in itertools.product(vect_search_space, mod_search_space)
]

rmse = make_scorer(mean_squared_error, squared=False, greater_is_better=False)  # to grid over rmse

mod = GridSearchCV(pipe, param_, cv=5, verbose=3, scoring=rmse, refit=True)
mod = mod.fit(dtrain.drop(['target'], axis=1), dtrain['target'])
print('Best pipeline is \n {},'.format(mod.best_estimator_))
# Best pipeline is
#  Pipeline(steps=[('vect',
#                  ColumnTransformer(transformers=[('vectorizer',
#                                                   HashingVectorizer(),
#                                                   'excerpt')])),
#                 ('model', SVR(C=1000, gamma=0.001))]),

############################### Save pipeline & calc result ##########################################################
# Save pipeline
joblib.dump(mod.best_estimator_, 'Deploy/src/model_pipeline.pkl')

def calc_rmse(data):
    y_predict = mod.predict(data)
    data['pred'] = y_predict
    rmse = mean_squared_error(data['target'], y_predict, squared=False)
    return print('Training RMSE {}, Calc RMSE {},'.format(round(-mod.best_score_, 3), round(rmse, 3)))

# Calc validation error
valid_error = calc_rmse(dvalid)
# Result - Test RMSE 0.745, Validation RMSE 0.747

# calc rmse on kagle submission sample
dtest = pd.read_csv('commonlitreadabilityprize/test.csv')
dtest = features_creation(dtest, 'excerpt')
y_predict = mod.predict(dtest)
dtest['target'] = y_predict
dtest[['id', 'target']].to_csv('submission.csv', index=False)






